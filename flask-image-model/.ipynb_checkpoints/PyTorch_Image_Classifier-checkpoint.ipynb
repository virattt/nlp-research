{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dRvUSHZsEb5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement unzip (from versions: none)\n",
      "ERROR: No matching distribution found for unzip\n"
     ]
    }
   ],
   "source": [
    "!pip install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "kmFYYBILsGAP",
    "outputId": "986d0f33-8c9e-4d19-d199-cf511843acb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Import PyTorch if using Google Colab\\n# http://pytorch.org/\\nfrom os.path import exists\\nfrom wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\\nplatform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\\ncuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\\\.\\\\([0-9]*\\\\)\\\\.\\\\([0-9]*\\\\)$/cu\\x01\\x02/'\\naccelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\\n\\n!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\\nimport torch\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Import PyTorch if using Google Colab\n",
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OLFfUZ_lsGE_",
    "outputId": "9e0b7d43-6347-4325-be29-1c104f6313a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Check PIL version if using Colab. If below 5.3, restart runtime and run again.\\nimport PIL\\nprint(PIL.PILLOW_VERSION)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Check PIL version if using Colab. If below 5.3, restart runtime and run again.\n",
    "import PIL\n",
    "print(PIL.PILLOW_VERSION)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WRXBfHJsGIa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Run this cell to download the Udacity flower set\n",
    "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
    "!unzip -qq flower_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z80-QQNDsGMk"
   },
   "outputs": [],
   "source": [
    "# Import resources\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EtzRpna1sGQz",
    "outputId": "2a91fee8-97b1-465d-d47c-59d1cd435265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are good to go!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('Bummer!  Training on CPU ...')\n",
    "else:\n",
    "    print('You are good to go!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baC8RfyxsGXY"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDQQeI0VsGch"
   },
   "outputs": [],
   "source": [
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6eJ9w9YsGi8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'flower_data\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7fb3f37cb551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0;32m     22\u001b[0m                                           data_transforms[x])\n\u001b[1;32m---> 23\u001b[1;33m                   for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Using the image datasets and the trainforms, define the dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7fb3f37cb551>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0;32m     22\u001b[0m                                           data_transforms[x])\n\u001b[1;32m---> 23\u001b[1;33m                   for x in ['train', 'valid']}\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Using the image datasets and the trainforms, define the dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlu\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    204\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlu\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlu\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[1;34m(self, dir)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mNo\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'flower_data\\\\train'"
     ]
    }
   ],
   "source": [
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid']}\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid']}\n",
    "\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBHkLjlYsGob"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0kk4MJbese6B",
    "outputId": "d4680509-a0a0-40b3-ab4b-6440bafa027f"
   },
   "outputs": [],
   "source": [
    "print(dataset_sizes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ci0fE8Tse9F"
   },
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "roAFvxS1sfAU",
    "outputId": "85f671f2-39d6-4f3c-d265-6c8fa7a166aa"
   },
   "outputs": [],
   "source": [
    "# Run this to test the data loader\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LnxoYvW0sfGG",
    "outputId": "83d869d7-d502-4c7b-85a2-4824a06e9b49"
   },
   "outputs": [],
   "source": [
    "# # Run this to test your data loader\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "rand_idx = np.random.randint(len(images))\n",
    "# print(rand_idx)\n",
    "print(\"label: {}, class: {}, name: {}\".format(labels[rand_idx].item(),\n",
    "                                               class_names[labels[rand_idx].item()],\n",
    "                                               cat_to_name[class_names[labels[rand_idx].item()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11325
    },
    "colab_type": "code",
    "id": "bLHN-uunsfMM",
    "outputId": "65124447-b069-4307-d50e-efa96b5c4820"
   },
   "outputs": [],
   "source": [
    "model_name = 'densenet' #vgg\n",
    "if model_name == 'densenet':\n",
    "    model = models.densenet161(pretrained=True)\n",
    "    num_in_features = 2208\n",
    "    print(model)\n",
    "elif model_name == 'vgg':\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    num_in_features = 25088\n",
    "    print(model.classifier)\n",
    "else:\n",
    "    print(\"Unknown model, please choose 'densenet' or 'vgg'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xxpu-O3bsfQJ"
   },
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def build_classifier(num_in_features, hidden_layers, num_out_features):\n",
    "   \n",
    "    classifier = nn.Sequential()\n",
    "    if hidden_layers == None:\n",
    "        classifier.add_module('fc0', nn.Linear(num_in_features, 102))\n",
    "    else:\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        classifier.add_module('fc0', nn.Linear(num_in_features, hidden_layers[0]))\n",
    "        classifier.add_module('relu0', nn.ReLU())\n",
    "        classifier.add_module('drop0', nn.Dropout(.6))\n",
    "        classifier.add_module('relu1', nn.ReLU())\n",
    "        classifier.add_module('drop1', nn.Dropout(.5))\n",
    "        for i, (h1, h2) in enumerate(layer_sizes):\n",
    "            classifier.add_module('fc'+str(i+1), nn.Linear(h1, h2))\n",
    "            classifier.add_module('relu'+str(i+1), nn.ReLU())\n",
    "            classifier.add_module('drop'+str(i+1), nn.Dropout(.5))\n",
    "        classifier.add_module('output', nn.Linear(hidden_layers[-1], num_out_features))\n",
    "        \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uJhshsnMsfJX",
    "outputId": "4151ea1c-7903-4330-a51c-93f7460bf9ef"
   },
   "outputs": [],
   "source": [
    "hidden_layers = None#[4096, 1024, 256][512, 256, 128]\n",
    "\n",
    "classifier = build_classifier(num_in_features, hidden_layers, 102)\n",
    "print(classifier)\n",
    "\n",
    " # Only train the classifier parameters, feature parameters are frozen\n",
    "if model_name == 'densenet':\n",
    "    model.classifier = classifier\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adadelta(model.parameters()) # Adadelta #weight optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    #optimizer_conv = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.001, momentum=0.9)\n",
    "    sched = optim.lr_scheduler.StepLR(optimizer, step_size=4)\n",
    "elif model_name == 'vgg':\n",
    "    model.classifier = classifier\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n",
    "    sched = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "193_EfcLsfDz"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def train_model(model, criterion, optimizer, sched, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        #sched.step()\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    #load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2601
    },
    "colab_type": "code",
    "id": "nkgn4OlRjleP",
    "outputId": "a7efa632-2cab-4c45-cb15-bd0c5a37d1e8"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "model.to(device)\n",
    "model = train_model(model, criterion, optimizer, sched, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l5RW-Ixkjliv",
    "outputId": "02a5016a-62e5-4726-f413-71f5dc2afd4b"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for inputs, labels in dataloaders['valid']:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Class with the highest probability is our predicted class\n",
    "    equality = (labels.data == outputs.max(1)[1])\n",
    "\n",
    "    # Accuracy is number of correct predictions divided by all predictions\n",
    "    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "    \n",
    "print(\"Test accuracy: {:.3f}\".format(accuracy/len(dataloaders['valid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX_N0uf_jlmm"
   },
   "outputs": [],
   "source": [
    "# Saving the checkpoint\n",
    "model.class_to_idx = image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "5Da_x_lojlq3",
    "outputId": "cbe055e6-6d18-4031-fdc1-35142a5f2a67"
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 2208,\n",
    "              'output_size': 102,\n",
    "              'epochs': epochs,\n",
    "              'batch_size': 64,\n",
    "              'model': models.densenet161(pretrained=True),\n",
    "              'classifier': classifier,\n",
    "              'scheduler': sched,\n",
    "              'optimizer': optimizer.state_dict(),\n",
    "              'state_dict': model.state_dict(),\n",
    "              'class_to_idx': model.class_to_idx\n",
    "             }\n",
    "   \n",
    "torch.save(checkpoint, 'checkpoint_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KX27swgUjlu-",
    "outputId": "83a94d19-c1ca-4f0b-f80f-3c96872984ba"
   },
   "outputs": [],
   "source": [
    "# Loading the checkpoint\n",
    "ckpt = torch.load('checkpoint_final.pth')\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHnNzT33lpgs"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# If you are uploading this to the Udacity Lab, you may need this cell\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from collections import namedtuple\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# If you used something other than 224x224 cropped images, set the correct size here\n",
    "image_size = 224\n",
    "# Values you used for normalizing the images. Default here are for\n",
    "# pretrained models from torchvision.\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qONYRG3lplp"
   },
   "outputs": [],
   "source": [
    "# Load a checkpoint and rebuild the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    optimizer = checkpoint['optimizer']\n",
    "    epochs = checkpoint['epochs']\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return model, checkpoint['class_to_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11271
    },
    "colab_type": "code",
    "id": "e7RabGl4lprO",
    "outputId": "b48aa6ae-7610-47aa-e9ba-d15c1e59d180"
   },
   "outputs": [],
   "source": [
    "model, class_to_idx = load_checkpoint('checkpoint_ic_d161.pth')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9_HdGLFlpwM"
   },
   "outputs": [],
   "source": [
    "idx_to_class = { v : k for k,v in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzRYs7lrmE1f"
   },
   "source": [
    "## Inference for Classification\n",
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asCFxWf_lp1q"
   },
   "outputs": [],
   "source": [
    "image_path = 'flower_data/valid/102/image_08006.jpg'\n",
    "img = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3zK4uQ6sB_n"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # tensor.numpy().transpose(1, 2, 0)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = preprocess(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgC5YYw1mNLq"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "aehqxsmumNR5",
    "outputId": "68d8f95c-0d79-403b-8127-f6089424e5c0"
   },
   "outputs": [],
   "source": [
    "with Image.open('flower_data/valid/102/image_08006.jpg') as image:\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxAO8oDamYFY"
   },
   "source": [
    "## Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hQ_QhsomNPl"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8hdmpb1mbJz"
   },
   "outputs": [],
   "source": [
    "model.class_to_idx = image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akLYLOcnmgaJ"
   },
   "outputs": [],
   "source": [
    "def predict2(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # Implement the code to predict the class from an image file\n",
    "    img = Image.open(image_path)\n",
    "    img = process_image(img)\n",
    "    \n",
    "    # Convert 2D image to 1D vector\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    \n",
    "    img = torch.from_numpy(img)\n",
    "    \n",
    "    model.eval()\n",
    "    inputs = Variable(img).to(device)\n",
    "    logits = model.forward(inputs)\n",
    "    \n",
    "    ps = F.softmax(logits,dim=1)\n",
    "    topk = ps.cpu().topk(topk)\n",
    "    \n",
    "    return (e.data.numpy().squeeze().tolist() for e in topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "1MMS4e_rmgso",
    "outputId": "b3370fa4-ea3b-46bb-83ab-cc6943b834b8"
   },
   "outputs": [],
   "source": [
    "img_path = 'flower_data/valid/18/image_04252.jpg'\n",
    "probs, classes = predict2(img_path, model.to(device))\n",
    "print(probs)\n",
    "print(classes)\n",
    "flower_names = [cat_to_name[class_names[e]] for e in classes]\n",
    "print(flower_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "P_rCY1n4mnCr",
    "outputId": "edaefaa4-5560-4eb1-fb28-ab551f139f0c"
   },
   "outputs": [],
   "source": [
    "def view_classify(img_path, prob, classes, mapping):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
    "    flower_name = mapping[img_path.split('/')[-2]]\n",
    "    ax1.set_title(flower_name)\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(prob))\n",
    "    ax2.barh(y_pos, prob, align='center')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(flower_names)\n",
    "    ax2.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax2.set_title('Class Probability')\n",
    "\n",
    "view_classify(img_path, probs, classes, cat_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16f_Xr8gPpbI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_Image_Classifier_Final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
